# üìä HR Analytics Data Lakehouse

> Um pipeline de dados End-to-End para an√°lise de People Analytics, utilizando arquitetura Medallion, AWS e Databricks.

![Status](https://img.shields.io/badge/Status-Em_Desenvolvimento-yellow)
![Python](https://img.shields.io/badge/Python-14354C?style=flat&logo=python&logoColor=white)
![Terraform](https://img.shields.io/badge/IaC-Terraform-purple)
![AWS](https://img.shields.io/badge/Cloud-AWS-orange)

## üéØ Objetivo do Projeto
Este projeto visa construir um **Data Lakehouse** para o departamento de Recursos Humanos. O objetivo √© monitorar indicadores cr√≠ticos como:
- Banco de Horas e Horas Extras.
- Frequ√™ncia e Absente√≠smo.
- Escalas de Trabalho.

A solu√ß√£o implementa um pipeline completo, desde a ingest√£o de dados brutos at√© a disponibiliza√ß√£o de KPIs para dashboards, garantindo governan√ßa, qualidade e escalabilidade.

---
## Arquitetura da Solu√ß√£o

O fluxo de dados foi desenhado para simular um ambiente corporativo real:

1.  **Gera√ß√£o de Dados (Source):** Scripts Python geram dados sint√©ticos complexos (JSON/CSV) simulando sistemas de RH e rel√≥gios de ponto IoT.
2.  **Ingest√£o (Bronze):** Carga dos dados brutos no Data Lake (S3/DBFS).
3.  **Refinamento (Silver):** Limpeza, deduplica√ß√£o, tratamento de tipos e regras de neg√≥cio (ex: c√°lculo de horas trabalhadas).
4.  **Agrega√ß√£o (Gold):** Tabelas modeladas (Star Schema) prontas para BI e Analytics.

--- 

## üöÄ Roadmap do Projeto

Abaixo, o status atual do desenvolvimento:

- [x] **M√≥dulo de Gera√ß√£o de Dados**
    - [x] Script de Funcion√°rios (L√≥gica de Pir√¢mide Hier√°rquica)
    - [x] Script de Ponto Eletr√¥nico (Simula√ß√£o de atrasos, faltas e escalas)
    - [x] Script de Carga Incremental (Turnover e Atualiza√ß√£o Di√°ria)
- [ ] **Ingest√£o de Dados (Camada Bronze)**
    - [ ] Configura√ß√£o do Databricks/S3
    - [ ] Ingest√£o de CSV e JSON (Autoloader/Copy Into)
- [ ] **Processamento (Camada Silver)**
    - [ ] Tratamento de Schema e Qualidade de Dados
    - [ ] Explode de JSONs aninhados
    - [ ] Regras de Neg√≥cio (C√°lculo de Jornada)
- [ ] **Modelagem (Camada Gold)**
    - [ ] Cria√ß√£o de Fatos e Dimens√µes
    - [ ] KPIs de RH
- [ ] **Orquestra√ß√£o & Dataviz**
    - [ ] Dashboards

---
## üõ†Ô∏è Tech Stack
|Categoria|Tecnologias|
|---------|-----------|
|Linguagem|Python 3.10, SQL|
|Cloud Provider|AWS (S3, Glue, IAM)
|Infra as Code|Terraform|
|Processamento|Apache Spark (PySpark), Delta Lake|
|Orquestra√ß√£o|Apache Airflow (via Astronomer)|
|Data Warehouse|Snowflake (Planejado)|
|Qualidade de Dados|Great Expectations (Planejado)|

---
## üìÇ Estrutura do Reposit√≥rio
```hr-analytics-pipeline/
‚îú‚îÄ‚îÄ astro_airflow/      # Orquestra√ß√£o (DAGs do Airflow)
‚îú‚îÄ‚îÄ infrastructure/     # C√≥digo Terraform (IaC)
‚îú‚îÄ‚îÄ src/                # Scripts Python e Spark
‚îÇ   ‚îú‚îÄ‚îÄ data_generator/ # Simula√ß√£o de dados de RH
‚îÇ   ‚îî‚îÄ‚îÄ glue_jobs/      # Jobs de ETL
‚îú‚îÄ‚îÄ notebooks/          # Sandbox para explora√ß√£o (Databricks)
‚îî‚îÄ‚îÄ tests/              # Testes unit√°rios
```

## üé≤ Como gerar os dados
Para gerar a massa de dados inicial, acesse a documenta√ß√£o espec√≠fica do m√≥dulo:
[üìñ Ir para Documenta√ß√£o do Gerador de Dados](./src/data_generator/README.md)

---
**Desenvolvido por Michael Cruz como parte do portf√≥lio de Engenharia de Dados.**