# ğŸ“Š HR Analytics Data Lakehouse

> Um pipeline de dados End-to-End para anÃ¡lise de People Analytics, utilizando arquitetura Medallion, AWS e Databricks.

![Status](https://img.shields.io/badge/Status-Em_Desenvolvimento-yellow)
![Python](https://img.shields.io/badge/Python-14354C?style=flat&logo=python&logoColor=white)
![Terraform](https://img.shields.io/badge/IaC-Terraform-purple)
![AWS](https://img.shields.io/badge/Cloud-AWS-orange)

## ğŸ¯ Objetivo do Projeto
Este projeto visa construir um **Data Lakehouse** para o departamento de Recursos Humanos. O objetivo Ã© monitorar indicadores crÃ­ticos como:
- Banco de Horas e Horas Extras.
- FrequÃªncia e AbsenteÃ­smo.
- Escalas de Trabalho.

A soluÃ§Ã£o implementa um pipeline completo, desde a ingestÃ£o de dados brutos atÃ© a disponibilizaÃ§Ã£o de KPIs para dashboards, garantindo governanÃ§a, qualidade e escalabilidade.

## Arquitetura da SoluÃ§Ã£o

A arquitetura segue o padrÃ£o **Medallion (Bronze, Silver, Gold)**, garantindo o refinamento progressivo dos dados.

## ğŸ› ï¸ Tech Stack
|Categoria|Tecnologias|
|---------|-----------|
|Linguagem|Python 3.10, SQL|
|Cloud Provider|AWS (S3, Glue, IAM)
|Infra as Code|Terraform|
|Processamento|Apache Spark (PySpark), Delta Lake|
|OrquestraÃ§Ã£o|Apache Airflow (via Astronomer)|
|Data Warehouse|Snowflake (Planejado)|
|Qualidade de Dados|Great Expectations (Planejado)|

## ğŸ“‚ Estrutura do RepositÃ³rio
```hr-analytics-pipeline/
â”œâ”€â”€ astro_airflow/      # OrquestraÃ§Ã£o (DAGs do Airflow)
â”œâ”€â”€ infrastructure/     # CÃ³digo Terraform (IaC)
â”œâ”€â”€ src/                # Scripts Python e Spark
â”‚   â”œâ”€â”€ data_generator/ # SimulaÃ§Ã£o de dados de RH
â”‚   â””â”€â”€ glue_jobs/      # Jobs de ETL
â”œâ”€â”€ notebooks/          # Sandbox para exploraÃ§Ã£o (Databricks)
â””â”€â”€ tests/              # Testes unitÃ¡rios
```

## ğŸš€ Como Executar (Em breve)
InstruÃ§Ãµes detalhadas de setup serÃ£o adicionadas conforme o desenvolvimento avanÃ§a.

---
**Desenvolvido por Michael Cruz como parte do portfÃ³lio de Engenharia de Dados.**