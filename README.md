# ğŸ“Š HR Analytics Data Lakehouse

> Um pipeline de dados End-to-End para anÃ¡lise de People Analytics, utilizando arquitetura Medallion, AWS e Databricks.

![Status](https://img.shields.io/badge/Status-Em_Desenvolvimento-yellow)
![Python](https://img.shields.io/badge/Python-14354C?style=flat&logo=python&logoColor=white)
![Terraform](https://img.shields.io/badge/IaC-Terraform-purple)
![AWS](https://img.shields.io/badge/Cloud-AWS-orange)

## ğŸ¯ Objetivo do Projeto
Este projeto visa construir um **Data Lakehouse** para o departamento de Recursos Humanos. O objetivo Ã© monitorar indicadores crÃ­ticos como:
- Banco de Horas e Horas Extras.
- FrequÃªncia e AbsenteÃ­smo.
- Escalas de Trabalho.

A soluÃ§Ã£o implementa um pipeline completo, desde a ingestÃ£o de dados brutos atÃ© a disponibilizaÃ§Ã£o de KPIs para dashboards, garantindo governanÃ§a, qualidade e escalabilidade.

---
## Arquitetura da SoluÃ§Ã£o

O fluxo de dados foi desenhado para simular um ambiente corporativo real:

1.  **GeraÃ§Ã£o de Dados (Source):** Scripts Python geram dados sintÃ©ticos complexos (JSON/CSV) simulando sistemas de RH e relÃ³gios de ponto IoT. Os arquivos sÃ£o gerados com versionamento por timestamp (`employees_20251217_1000.csv`).
2.  **IngestÃ£o (Bronze):** IngestÃ£o via **Databricks Autoloader** (`cloudFiles`).
    - Utiliza **Spark Structured Streaming** em modo `AvailableNow` (Batch).
    - Schema Evolution e Schema Inference ativados.
    - Armazena histÃ³rico completo (Full Snapshot Append-Only).
3.  **Refinamento (Silver):** (Em breve) Limpeza, deduplicaÃ§Ã£o (Merge), tratamento de tipos e regras de negÃ³cio.
4.  **AgregaÃ§Ã£o (Gold):** (Em breve) Tabelas modeladas (Star Schema) prontas para BI e Analytics.


--- 

## ğŸš€ Roadmap do Projeto

Abaixo, o status atual do desenvolvimento:

- [x] **MÃ³dulo de GeraÃ§Ã£o de Dados**
    - [x] Script de FuncionÃ¡rios (LÃ³gica de PirÃ¢mide HierÃ¡rquica)
    - [x] Script de Ponto EletrÃ´nico (SimulaÃ§Ã£o de atrasos, faltas e escalas)
    - [x] Script de Carga Incremental (Turnover e AtualizaÃ§Ã£o DiÃ¡ria)
- [x] **IngestÃ£o de Dados (Camada Bronze)**
    - [x] ConfiguraÃ§Ã£o do Unity Catalog e Volumes
    - [x] Pipeline de IngestÃ£o com Autoloader (CSV e JSON)
    - [x] Captura de Metadados (`_metadata.file_path`, `data_ingestao`)
- [ ] **Processamento (Camada Silver)**
    - [ ] Tratamento de Schema e Qualidade de Dados
    - [ ] Explode de JSONs aninhados
    - [ ] Regras de NegÃ³cio (CÃ¡lculo de Jornada)
- [ ] **Modelagem (Camada Gold)**
    - [ ] CriaÃ§Ã£o de Fatos e DimensÃµes
    - [ ] KPIs de RH
- [ ] **OrquestraÃ§Ã£o & Dataviz**
    - [ ] Dashboards

---
## ğŸ› ï¸ Tech Stack
|Categoria|Tecnologias|
|---------|-----------|
|Linguagem|Python 3.10, SQL|
|Cloud Provider|AWS (S3, Glue, IAM, Databricks Community)
|Infra as Code|Terraform|
|Processamento|Apache Spark (PySpark), Delta Lake|
|CatÃ¡logo de Dados|Unity Catalog|
|OrquestraÃ§Ã£o|Apache Airflow (via Astronomer), Databricks Workflows (Planejado)|
|Data Warehouse|Snowflake (Planejado)|
|Qualidade de Dados|Great Expectations (Planejado)|

---
## ğŸ“‚ Estrutura do RepositÃ³rio
```hr-analytics-pipeline/
â”œâ”€â”€ astro_airflow/      # (Em breve) OrquestraÃ§Ã£o (DAGs do Airflow)
â”œâ”€â”€ infrastructure/     # CÃ³digo Terraform (IaC)
â”œâ”€â”€ src/                # Scripts Python e Spark
â”‚   â”œâ”€â”€ data_generator/ # SimulaÃ§Ã£o de dados de RH
â”‚   â”œâ”€â”€ 00-bronze/      # Notebooks de IngestÃ£o (Autoloader)
â”‚   â”œâ”€â”€ 01-silver/      # (Em breve) Notebooks de Tratamento
â”‚   â”œâ”€â”€ 02-gold/        # (Em breve) Notebooks de AgregaÃ§Ã£o
â”‚   â””â”€â”€ glue_jobs/      # (Em breve) Jobs de ETL
â”œâ”€â”€ notebooks/          # Sandbox para exploraÃ§Ã£o (Databricks)
â””â”€â”€ tests/              # Testes unitÃ¡rios
```

## ğŸ² Como gerar os dados
Para gerar a massa de dados inicial, acesse a documentaÃ§Ã£o especÃ­fica do mÃ³dulo:
[ğŸ“– Ir para DocumentaÃ§Ã£o do Gerador de Dados](./src/data_generator/README.md)

## ğŸ¥‰ DocumentaÃ§Ã£o da Camada Bronze
Para entender os detalhes tÃ©cnicos da ingestÃ£o:
[ğŸ“– Ir para DocumentaÃ§Ã£o da Bronze](./src/00-bronze/README.md)
---
**Desenvolvido por Michael Cruz como parte do portfÃ³lio de Engenharia de Dados.**